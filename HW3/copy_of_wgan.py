# -*- coding: utf-8 -*-
"""Copy of wgan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HLO02RzYkYGN4M-MhvXE4ynovU9T0tCU
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x
import os
import tensorflow as tf
os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"   # see issue #152
os.environ["CUDA_VISIBLE_DEVICES"]="0"
from __future__ import print_function
from six.moves import xrange
import tensorflow.contrib.slim as slim
import os

import numpy as np
import tensorflow.contrib.layers as ly
from tensorflow.examples.tutorials.mnist import input_data
from functools import partial
import pickle
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

cd drive

cd My Drive

def read_image():
    f=open('gan_dataset/data_batch_'+str(1),'rb')
    data=pickle.load(f,encoding='bytes')
    image_input=data[b'data']

    for i in range(2,6):
        f=open('gan_dataset/data_batch_'+str(i),'rb')
        data=pickle.load(f,encoding='bytes')
        image_input=np.concatenate((image_input,data[b'data']),axis=0)
        f.close()

    return image_input

image_input=read_image()

image_input2=[]
for i in image_input:
    image_input2.append(np.reshape(i.reshape(3,32,32),3072,order='F'))

image_input3=np.array(image_input2).reshape(50000,32,32,3)

session = tf.Session()
image_input4=session.run(tf.image.resize_images(image_input3,(64,64)))

image_input=image_input4/255

def lrelu(x, leak=0.3, name="lrelu"):
    with tf.variable_scope(name):
        f1 = 0.5 * (1 + leak)
        f2 = 0.5 * (1 - leak)
        return f1 * x + f2 * abs(x)

batch_size = 64
z_dim = 100
learning_rate_ger = 5e-5
learning_rate_dis = 5e-5
device = '/gpu:0'

s = 64
Citers = 5
clamp_lower = -0.01
clamp_upper = 0.01
channel = 3
mode = 'gp'
is_adam=False
lam = 10.
s2, s4, s8, s16 =\
    int(s / 2), int(s / 4), int(s / 8), int(s / 16)

ngf = 64
ndf = 64
log_dir = './log_wgan'
ckpt_dir = './ckpt_wgan'
if not os.path.exists(ckpt_dir):
    os.makedirs(ckpt_dir)
max_iter_step = 20000

def generator_conv(z):
    train = ly.fully_connected(
        z, 4 * 4 * 512, activation_fn=lrelu, normalizer_fn=ly.batch_norm)
    train = tf.reshape(train, (-1, 4, 4, 512))
    train = ly.conv2d_transpose(train, 256, 5, stride=2,
                                activation_fn=tf.nn.relu, normalizer_fn=ly.batch_norm, padding='SAME', weights_initializer=tf.random_normal_initializer(0, 0.02))
    train = ly.conv2d_transpose(train, 128, 5, stride=2,
                                activation_fn=tf.nn.relu, normalizer_fn=ly.batch_norm, padding='SAME', weights_initializer=tf.random_normal_initializer(0, 0.02))
    train = ly.conv2d_transpose(train, 64, 5, stride=2,
                                activation_fn=tf.nn.relu, normalizer_fn=ly.batch_norm, padding='SAME', weights_initializer=tf.random_normal_initializer(0, 0.02))
    train = ly.conv2d_transpose(train, channel, 5, stride=2,
                                activation_fn=tf.nn.tanh, padding='SAME', weights_initializer=tf.random_normal_initializer(0, 0.02))
    print(train.name)
    return train

def critic_conv(img, reuse=False):
    with tf.variable_scope('critic') as scope:
        if reuse:
            scope.reuse_variables()
        size = 64

        img = ly.conv2d(img, num_outputs=size, kernel_size=5,
                        stride=2, activation_fn=lrelu)

        img = ly.conv2d(img, num_outputs=size * 2, kernel_size=5,
                        stride=2, activation_fn=lrelu, normalizer_fn=ly.batch_norm)

        img = ly.conv2d(img, num_outputs=size * 4, kernel_size=5,
                        stride=2, activation_fn=lrelu, normalizer_fn=ly.batch_norm)

        img = ly.conv2d(img, num_outputs=size * 8, kernel_size=5,
                        stride=2, activation_fn=lrelu, normalizer_fn=ly.batch_norm)

        logit = ly.fully_connected(tf.reshape(
            img, [batch_size, -1]), 1, activation_fn=None)

    return logit

#     z = tf.placeholder(tf.float32, shape=(batch_size, z_dim))
noise_dist = tf.contrib.distributions.Normal(0., 1.)
z = noise_dist.sample((batch_size, z_dim))
generator = generator_conv
critic = critic_conv
with tf.variable_scope('generator'):
    train = generator(z)
real_data = tf.placeholder(
    dtype=tf.float32, shape=(batch_size, 64, 64, channel))
true_logit = critic(real_data)
fake_logit = critic(train, reuse=True)
c_loss = tf.reduce_mean(fake_logit - true_logit)
if mode is 'gp':
    alpha_dist = tf.contrib.distributions.Uniform(low=0., high=1.)
    alpha = alpha_dist.sample((batch_size, 1, 1, 1))
    interpolated = real_data + alpha*(train-real_data)
    inte_logit = critic(interpolated, reuse=True)
    gradients = tf.gradients(inte_logit, [interpolated,])[0]
    grad_l2 = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1,2,3]))
    gradient_penalty = tf.reduce_mean((grad_l2-1)**2)
    gp_loss_sum = tf.summary.scalar("gp_loss", gradient_penalty)
    grad = tf.summary.scalar("grad_norm", tf.nn.l2_loss(gradients))
    c_loss += lam*gradient_penalty



g_loss = tf.reduce_mean(-fake_logit)
g_loss_sum = tf.summary.scalar("g_loss", g_loss)
c_loss_sum = tf.summary.scalar("c_loss", c_loss)
img_sum = tf.summary.image("img", train, max_outputs=10)
theta_g = tf.get_collection(
    tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator')
theta_c = tf.get_collection(
    tf.GraphKeys.TRAINABLE_VARIABLES, scope='critic')
counter_g = tf.Variable(trainable=False, initial_value=0, dtype=tf.int32)
opt_g = ly.optimize_loss(loss=g_loss, learning_rate=learning_rate_ger,
                    optimizer=partial(tf.train.AdamOptimizer, beta1=0.5, beta2=0.9) if is_adam is True else tf.train.RMSPropOptimizer, 
                    variables=theta_g, global_step=counter_g,
                    summaries = ['gradient_norm'])
counter_c = tf.Variable(trainable=False, initial_value=0, dtype=tf.int32)
opt_c = ly.optimize_loss(loss=c_loss, learning_rate=learning_rate_dis,
                    optimizer=partial(tf.train.AdamOptimizer, beta1=0.5, beta2=0.9) if is_adam is True else tf.train.RMSPropOptimizer, 
                    variables=theta_c, global_step=counter_c,
                    summaries = ['gradient_norm'])
if mode is 'regular':
    clipped_var_c = [tf.assign(var, tf.clip_by_value(var, clamp_lower, clamp_upper)) for var in theta_c]
    # merge the clip operations on critic variables
    with tf.control_dependencies([opt_c]):
        opt_c = tf.tuple(clipped_var_c)
if not mode in ['gp', 'regular']:
    raise(NotImplementedError('Only two modes'))

merged_all = tf.summary.merge_all()
saver = tf.train.Saver()
config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)
config.gpu_options.allow_growth = True
config.gpu_options.per_process_gpu_memory_fraction = 0.8

with tf.Session(config=config) as sess:
  sess.run(tf.global_variables_initializer())
  batch=image_input[0:0+batch_size]
  a=sess.run(train, feed_dict={real_data:batch})

m=0
loss_g_list=[]
loss_c_list=[]
sess = tf.Session()
sess.run(tf.global_variables_initializer())
summary_writer = tf.summary.FileWriter(log_dir, sess.graph)
for i in range(max_iter_step):

    if i%130==0:
      batch=image_input[m:m+batch_size]
      m=m+batch_size
      fake_image,loss_g,loss_c = sess.run([train,g_loss,c_loss], feed_dict={real_data:batch})
      print('epoch: '+str(int(i/781))+', loss_g: '+str(loss_g)+', loss_c: '+str(loss_c))
      loss_g_list.append(loss_g)
      loss_c_list.append(loss_c)
      plt.imshow(fake_image[0])
      plt.show()
      pickle.dump(fake_image,open('wgan_result2/epoch_'+str(int(i/130))+'.p','wb'))
      m=0
      continue

    for j in range(0,5):
        batch=image_input[m:m+batch_size]
        m=m+batch_size
        if i % 100 == 99 and j == 0:
            run_options = tf.RunOptions(
                trace_level=tf.RunOptions.FULL_TRACE)
            run_metadata = tf.RunMetadata()
            _, merged = sess.run([opt_c, merged_all], feed_dict={real_data:batch},
                                  options=run_options, run_metadata=run_metadata)
            summary_writer.add_summary(merged, i)
            summary_writer.add_run_metadata(
                run_metadata, 'critic_metadata {}'.format(i), i)
        else:
            sess.run(opt_c, feed_dict={real_data:batch})               

    batch=image_input[m:m+batch_size]
    m=m+batch_size
    if i % 100 == 99:
        _, merged = sess.run([opt_g, merged_all], feed_dict={real_data:batch},
              options=run_options, run_metadata=run_metadata)
        summary_writer.add_summary(merged, i)
        summary_writer.add_run_metadata(
            run_metadata, 'generator_metadata {}'.format(i), i)
    else:
        sess.run(opt_g, feed_dict={real_data:batch})                
    if i % 1000 == 999:
        saver.save(sess, os.path.join(
            ckpt_dir, "model.ckpt"), global_step=i)

import matplotlib.pyplot as plt
plt.plot(loss_g_list[0:100])
plt.plot(loss_c_list[0:100])
plt.title('WGAN loss')
plt.ylabel('loss' )
plt.xlabel('epoch')
plt.show()

